The repository compares the two image-text matching models Negative Aware Attention Framework (NAAF) and Contrastive Language-Image Pretraining (CLIP) model on the subset of Flickr30K dataset. Given the image, NAAF and CLIP retrieve the best suitable text from the available. This work is based on the following two papers https://github.com/CrossmodalGroup/NAAF and https://github.com/openai/CLIP.
